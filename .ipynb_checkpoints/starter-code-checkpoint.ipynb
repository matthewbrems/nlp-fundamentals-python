{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This iiiiiis Jeopardyyy!\n",
    "\n",
    "> [Source of Dataset](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages.\n",
    "# !pip3 install pandas regex sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "\n",
    "1. Import and explore our data using `pandas`.\n",
    "2. Clean our text data.\n",
    "3. Vectorize our text data.\n",
    "4. Fit model.\n",
    "5. Evaluate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and explore our data using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read our Jeopardy data in.\n",
    "jeopardy = pd.read_csv('./jeopardy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the first five rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert air_date to a datetime column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the latest air_date?\n",
    "max(jeopardy['air_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the earliest air_date?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the breakdown of questions by round?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the breakdown of questions by category?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can I filter my dataframe to see all\n",
    "# questions in a Tiebreaker round?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean our text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine zero-th question.\n",
    "jeopardy['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine first question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine second question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is particularly clean. But our \"toolbox\" for cleaning text data includes many things of which we may want to be aware:\n",
    "- Convert all words to lower case.\n",
    "- Tokenize text.\n",
    "- Remove HTML artifacts.\n",
    "- Remove punctuation.\n",
    "- Lemmatize/stem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert words to lower case.\n",
    "\n",
    "As Python is case-sensitive (as are most languages!), we often want to make apples-to-apples comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine zero-th question.\n",
    "jeopardy['question'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on how we create columns of data, the `For` and `for` may be interpreted differently, even though these are the same word!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print string in lower case.\n",
    "jeopardy['question'][0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lower_case variable.\n",
    "lower_case ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize text.\n",
    "\n",
    "When we **tokenize** text data, we split a string into smaller strings based on some pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .split() to tokenize our text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokens.\n",
    "tokens ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Why do you think tokenizing might be beneficial?</summary>\n",
    "\n",
    "- It allows us to iterate through each token in our list to clean separately/individually.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can use regular expressions to detect specific patterns, in case we want to do something more specific than just split items based one specific character string, like spaces.\n",
    "> The `nltk` library includes the `RegexpTokenizer()` function if you want to tokenize based on this specific pattern. Below, we'll see some examples of patterns we can identify!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use re.findall to find all tokens with a numeric digit.\n",
    "\n",
    "for token in tokens:\n",
    "    print(re.findall('\\d+', token), token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use re.findall to split tokens up containing punctuation.\n",
    "\n",
    "for token in tokens:\n",
    "    print(re.findall('\\w+|\\$[\\d\\.]+|\\S+', token), token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use re.findall to select words beginning with a capital letter.\n",
    "\n",
    "for token in tokens:\n",
    "    print(re.findall('[A-Z]\\w+', token), token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use re.findall to select words beginning with a capital letter.\n",
    "\n",
    "for token in jeopardy['question'][0].split():\n",
    "    print(re.findall('[A-Z]\\w+', token), token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use re.findall to get non-letters and non-numbers.\n",
    "for token in tokens:\n",
    "    print(re.findall('[^a-zA-Z0-9]', token), token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove HTML artifacts.\n",
    "\n",
    "It is unlikely that any of these Jeopardy questions contain HTML artifacts that we'd want to discard, so we won't do that here. However, HTML code snippets (like `<br>` or `\\`) might be interpreted incorrectly by a vectorizer.\n",
    "> The `bs4` library includes a `BeautifulSoup` object and `.get_text()` method if you want to remove code snippets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize/stem words.\n",
    "\n",
    "Some words may have similar meaning, but be spelled differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine zero-th question.\n",
    "jeopardy['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine second question.\n",
    "jeopardy['question'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to combine these words together, we might use a lemmatizer or stemmer. Lemmatizers and stemmers are not perfect. They're inexact!\n",
    "- Lemmatizers tend to be \"gentler.\" It changes fewer words, but may have more false negatives. (Words that should be changed, but aren't.)\n",
    "- Stemmers tend to be \"cruder.\" It changes more words, but may have more false positives. (Words that should not be changed, but are changed anyway.)\n",
    "\n",
    "> The `nltk` library contains lemmatizers and stemmers. I've used the `WordNetLemmatizer()` and the `PorterStemmer()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put into one function and clean Jeopardy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jeopardy_clean(input_text):\n",
    "    # The input is a single string (one question), and \n",
    "    # the output is a single string (a cleaned question).\n",
    "    \n",
    "    # 1. Remove any punctuation.\n",
    "    letters_numbers = re.sub(\"[^a-zA-Z0-9]\", \" \", input_text)\n",
    "    \n",
    "    # 2. Convert to lower case. \n",
    "    lower_case = letters_numbers.lower()\n",
    "    \n",
    "    # 3. split into individual words.\n",
    "    words = lower_case.split()\n",
    "    \n",
    "    # If you wanted to add more in here, like:\n",
    "    # removing HTML artifact,\n",
    "    # lemmatizing/stemming,\n",
    "    # removing stopwords,\n",
    "    # then you could do that here!\n",
    "    \n",
    "    # 4. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list for our cleaned Jeopardy data.\n",
    "clean_jeopardy = []\n",
    "\n",
    "# How many questions do we have?\n",
    "total_questions = len(jeopardy['question'])\n",
    "\n",
    "print(\"Cleaning the Jeopardy questions...\")\n",
    "\n",
    "# Instantiate counter.\n",
    "count = 0\n",
    "\n",
    "# For every question in our data...\n",
    "for question in jeopardy['question']:\n",
    "    \n",
    "    # Clean question, then append to clean_jeopardy.\n",
    "    clean_jeopardy.append(jeopardy_clean(question))\n",
    "    \n",
    "    # If the index is divisible by 10,000, print a message.\n",
    "    if (count + 1) % 10_000 == 0:\n",
    "        print(f'Review {count + 1} of {total_questions}.')\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "# Let's do the same for our testing set.\n",
    "print(f'Done! Completed all {total_questions} questions.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine first ten questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize our text data.\n",
    "\n",
    "We have our cleaned data! Now we can start preparing our model.\n",
    "\n",
    "In machine learning:\n",
    "- `X` is a matrix/dataframe of real numbers.\n",
    "- `y` is a vector/series of real numbers.\n",
    "\n",
    "Our $Y$ variable will be, \"Was this question asked during the 'Double Jeopardy!' round?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our y variable.\n",
    "y = pd.Series([1 if item == 'Double Jeopardy!' else 0 for item in jeopardy['round']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm we created our variable correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['round'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our X variable.\n",
    "X = pd.DataFrame(clean_jeopardy, columns=['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['question'],\n",
    "                                                    y,\n",
    "                                                    test_size=0.2, # 20% of our data is test.\n",
    "                                                    stratify=y,    # keep distribution of y same \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text data (natural language data) is often not already organized as a matrix or vector of real numbers. **Vectorizing our text data** describes one common process for converting a set of text data into a matrix of real numbers.\n",
    "\n",
    "There are two basic, common types of vectorizer: `CountVectorizer` and `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer\n",
    "\n",
    "<img src=\"./images/countvectorizer.png\" alt=\"drawing\" width=\"700\"/>\n",
    "\n",
    "[Source.](https://towardsdatascience.com/nlp-learning-series-part-2-conventional-methods-for-text-classification-40f2839dd061)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer.\n",
    "\n",
    "cvec ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer on our corpus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the corpus.\n",
    "\n",
    "X_train ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_train into a DataFrame.\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train.toarray(),\n",
    "                          columns=cvec.get_feature_names())\n",
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data.\n",
    "X_test = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tokens are now stored as a bag-of-words. This is a simplified way of looking at and storing our data.\n",
    "- Bag-of-words representations discard grammar, order, and structure in the text but track occurrences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What might be some of the advantages of using this bag-of-words approach when modeling?</summary>\n",
    "\n",
    "- Efficient to store.\n",
    "- Efficient to model.\n",
    "- Keeps a decent amount of information.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What might be some of the disadvantages of using this bag-of-words approach when modeling?</summary>\n",
    "\n",
    "- Since bag-of-words models discard grammar, order, structure, and context, we lose a decent amount of information.\n",
    "- Phrases like \"not bad\" or \"not good\" won't be interpreted properly.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate logistic regression model.\n",
    "\n",
    "lr = LogisticRegression(solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression model.\n",
    "\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model accuracy on training data.\n",
    "\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model accuracy on testing data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer\n",
    "\n",
    "<img src=\"./images/tfidfvectorizer.png\" alt=\"drawing\" width=\"900\"/>\n",
    "\n",
    "[Source.](https://towardsdatascience.com/nlp-learning-series-part-2-conventional-methods-for-text-classification-40f2839dd061)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['question'],\n",
    "                                                    y,\n",
    "                                                    test_size=0.2, # 20% of our data is test.\n",
    "                                                    stratify=y,    # keep distribution of y same \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Instantiate TfidfVectorizer.\n",
    "tvec = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer and transform the training data.\n",
    "X_train = tvec.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data.\n",
    "X_test = tvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate logistic regression model.\n",
    "lr = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "# Fit logistic regression model.\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Get model accuracy on training data.\n",
    "print(lr.score(X_train, y_train))\n",
    "\n",
    "# Get model accuracy on testing data.\n",
    "print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<details><summary>What is a hyperparameter?</summary>\n",
    "\n",
    "- A hyperparameter is a built-in option that affects our model, but our model cannot learn these from our data!\n",
    "- Examples of hyperparameters include:\n",
    "    - the value of $k$ and the distance metric in $k$-nearest neighbors,\n",
    "    - our regularization constants $\\alpha$ or $C$ in linear and logistic regression.\n",
    "</details>\n",
    "\n",
    "There are many different hyperparameters of `CountVectorizer` that can affect the fit of our model!\n",
    "- `stop_words`\n",
    "- `max_features`, `max_df`, `min_df`\n",
    "- `ngram_range`\n",
    "\n",
    "\n",
    "#### `stop_words`\n",
    "\n",
    "Some words are so common that they may not provide legitimate information about the $Y$ variable we're trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at sklearn's stopwords.\n",
    "print(CountVectorizer(stop_words = 'english').get_stop_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CountVectorizer` gives you the option to eliminate stopwords from your corpus when instantiating your vectorizer.\n",
    "\n",
    "```python\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "```\n",
    "\n",
    "You can optionally pass your own list of stopwords that you'd like to remove.\n",
    "```python\n",
    "cvec = CountVectorizer(stop_words=['list', 'of', 'words', 'to', 'stop'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary size\n",
    "\n",
    "---\n",
    "One downside to `CountVectorizer` and `TfidfVectorizer` is the size of its vocabulary (`cvec.get_feature_names()`) can get really large. We're creating one column for every unique token in your corpus of data!\n",
    "\n",
    "There are three hyperparameters to help you control this.\n",
    "\n",
    "1. You can set `max_features` to only include the $N$ most popular vocabulary words in the corpus.\n",
    "\n",
    "```python\n",
    "cvec = CountVectorizer(max_features=1_000) # Only the top 1,000 words from the entire corpus will be saved\n",
    "```\n",
    "\n",
    "2. You can tell `CountVectorizer` to only consider words that occur in **at least** some number of documents.\n",
    "\n",
    "```python\n",
    "cvec = CountVectorizer(min_df=2) # A word must occur in at least two documents from the corpus\n",
    "```\n",
    "\n",
    "3. Conversely, you can tell `CountVectorizer` to only consider words that occur in **at most** some percentage of documents.\n",
    "\n",
    "```python\n",
    "cvec = CountVectorizer(max_df=.98) # Ignore words that occur in > 98% of the documents from the corpus\n",
    "```\n",
    "\n",
    "Both `max_df` and `min_df` can accept either an integer or a float.\n",
    "- An integer tells us the number of documents.\n",
    "- A float tells us the percentage of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Why might we want to control these vocabulary size hyperparameters?</summary>\n",
    "    \n",
    "- If we have too many features, our models may take a **very** long time to fit.\n",
    "- Control for overfitting/underfitting.\n",
    "- Words in 99% of documents or words occuring in only one document might not be very informative.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ngram_range`\n",
    "\n",
    "---\n",
    "\n",
    "`CountVectorizer` has the ability to capture $n$-word phrases, also called $n$-grams. Consider the following:\n",
    "\n",
    "> The quick brown fox jumps over the lazy dog.\n",
    "\n",
    "In the example sentence, the 2-grams are:\n",
    "- 'the quick'\n",
    "- 'quick brown'\n",
    "- 'brown fox'\n",
    "- 'fox jumps'\n",
    "- 'jumps over'\n",
    "- 'over the'\n",
    "- 'the lazy'\n",
    "- 'lazy dog'\n",
    "\n",
    "The `ngram_range` determines what $n$-grams should be considered as features.\n",
    "\n",
    "```python\n",
    "cvec = CountVectorizer(ngram_range=(1,2)) # Captures every 1-gram and every 2-gram\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>How many 3-grams would be generated from the phrase \"the quick brown fox jumps over the lazy dog?\"</summary>\n",
    "\n",
    "- Seven 3-grams.\n",
    "    - 'the quick brown'\n",
    "    - 'quick brown fox'\n",
    "    - 'brown fox jumps'\n",
    "    - 'fox jumps over'\n",
    "    - 'jumps over the'\n",
    "    - 'over the lazy'\n",
    "    - 'the lazy dog'\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Why might we want to change ngram_range to something other than (1,1)?</summary>\n",
    "\n",
    "- We can work with multi-word phrases like \"not good\" or \"very hot.\"\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "---\n",
    "\n",
    "We may want to test lots of different values of hyperparameters in our `CountVectorizer` and `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['question'],\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is GridSearch?</summary>\n",
    "    \n",
    "- GridSearch allows us to try different values of different hyperparameters, measure our model's performance on each one, and return the best model.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. LogisticRegression (estimator)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(solver = 'liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 1,000 and 2,000.\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "# Check removing English stopwords and not removing any stopwords.\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [1_000, 2_000],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'cvec__stop_words': ['english', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec = GridSearchCV(, # what object are we optimizing?\n",
    "                       , # what parameter values are we searching?\n",
    "                       ) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>How many models are we fitting here?</summary>\n",
    "\n",
    "- 2 max_features\n",
    "- 2 ngram_range\n",
    "- 2 stop_words\n",
    "- 5-fold CV\n",
    "- 2 * 2 * 2 * 5 = 40 models\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "gs_cvec.fit(X_train, y_train)\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy on training data.\n",
    "gs_cvec.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy on testing data.\n",
    "gs_cvec.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What model performed best?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All at once, now, with `TfidfVectorizer`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['question'],\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Let's set a pipeline up with two stages:\n",
    "# 1. TfidfVectorizer (transformer)\n",
    "# 2. LogisticRegression (estimator)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 1,000 and 2,000.\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "# Check removing English stopwords and not removing any stopwords.\n",
    "\n",
    "pipe_params = {\n",
    "    'tvec__max_features': [1_000, 2_000],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'tvec__stop_words': ['english', None]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "gs_tvec = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                       param_grid=pipe_params, # what parameters values are we searching?\n",
    "                       cv=5) # 5-fold cross-validation.\n",
    "\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "gs_tvec.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy on training data.\n",
    "print(f'Accuracy score on training data: {gs_tvec.score(X_train, y_train)}.')\n",
    "\n",
    "# Evaluate accuracy on testing data.\n",
    "print(f'Accuracy score on testing data: {gs_tvec.score(X_test, y_test)}.')\n",
    "\n",
    "# What model performed best?\n",
    "print(f'Best parameter values: {gs_tvec.best_params_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
